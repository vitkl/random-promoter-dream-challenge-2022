{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b36791b-6961-44d3-9341-bf44e9c781e1",
   "metadata": {},
   "source": [
    "# Describing the problem & goals of this test\n",
    "\n",
    "## Testing 2bp resolution in 2nd layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee6aae-7d49-4a35-b3c4-3ce972285cb5",
   "metadata": {},
   "source": [
    "### Task & data\n",
    "\n",
    "I chose sequence to expression task because the random promoter data recently generated by Carl de Boer lab allow us to quickly prototype and determine model architectures that are capable of predicting gene expression readout. This data describes transcriptional activity of just one yeast cell state but across 10 million random sequences which explore regulatory sequence space more deeply than you could by training models on the natural yeast genome. It was formatted in a way that makes it convenient to start with, whereas majority of problems relevant to perturbing aged and disfunctional cell states would require analysis and processing likely to take months to optimise. This makes this data a convenient starting point.\n",
    "\n",
    "An important caveat is that the models optimised to perform well on this data would quite possibly not perform optimally for predicting total RNA abundance in human, mouse and other ageing-relevant model organisms because these organisms have more cell types and more complex regulation than yeast (yeast scRNA https://www.nature.com/articles/s42003-021-02320-w, not that many regulatory states https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000224). The required specificity of transcription in vertebrates is going to require both 1) more complex interactions between transcription factors that bind to the promoter sequence near the transcription start site and 2) more complex interactions between transcription factors binding to the promoter and binding to the distal regulatory sites (the regulation become more complex at the origin of multicellularity 10.1016/j.cell.2016.03.034 and in general enabled complexity increase https://pubmed.ncbi.nlm.nih.gov/37390583/).\n",
    "\n",
    "In addition, yeast don't have complex 3D genome organisation such as TAD domains and have more limited utilisation of activity associated compartments. It is also likely that major gene regulation rules responsible for specification of cell states are different in vertebrates compared to yeast (active area of study, for example by Arnau Sebe-Pedros, Heather Marlow labs). However, a model that will succeed in mammals should likely be sufficiently complex to deal with this relatively simple data. Therefore, this data provides a quick test of model architecture robustness.\n",
    "\n",
    "The additional problem with this task is that to explain how the same genome is used by and leads to different cell states, we need to consider not just the genome sequence but which transcription factors and other regulatory proteins are present in those cell states. In contrast, this data presents the genome as if it was a static entity that always leads to the same activity. This task is not a realistic task necessary for identifying how to perturb aged or dysfunctional cells.\n",
    "\n",
    "### Bayesian modelling, CNN & what is tested here\n",
    "\n",
    "Bayesian modelling is not very frequently used in industry for large scale models. However, it provides a principled and intuitive way to include prior information about biology as inductive biases on model parameters - in addition to providing inductive biases in model architecture. In addition, there are statistical arguments why maximum likelihood inference leads to suboptimal solution for high-dimensional problems and where estimating variational posterior could lead to estimates that are closer to ground truth.\n",
    "\n",
    "Even when Bayesian models are not used with parameters informed by measurements external to the training task, the priors can be useful for specifying reasonable ranges of values and default behavior of the model. For example, if we want to learn assay sensitivity, we may want to regularize the parameter that represents assay sensitivity to be close to 1 to avoid over-normalizing biological differences. Similarly, we can regularise convolutional neural network weights that represent transcription factor DNA recognition preference to be either 1) small, thus implicitly requesting the model to learn simpler motifs, or 2) similar to experimentally determined motifs for transcription factors, which are extremely well characterized in yeast, so should provide a very good reference for this model. Both settings are tested in this experiment.\n",
    "\n",
    "In this task, we are going to train a simple Bayesian conditional neural network, which predicts the same outputs as the winning solution of the random promoter challenge. Winning solution of defined a dual likelihood for MPRA data that didn't just predict estimated average sequence activity (output of pre-processing workflow), but also predicted in which of the FACS bins a signal will be observed. The winning approach uses the inductive bias about how the experiment was designed, predicting which sequences are detected in which FACS sorting bins. FACS sorting was done according to reporter protein fluorescence - an approach where the measurement for every sequence is not readout on a continous scale but instead quantified in bins. In general, MPRA technologies with both sequencing and FACS readout could benefit from better formalized likelihoods that don't require arbitrary preprocessing of experimentally measured values (we could collaborate with Lars Velten, Jay Shendure labs to optimise this).\n",
    "\n",
    "Since this data is quite simple, representing both one cell state and yeast, an organism with relatively simple regulation, we likely don't need very complex models such as Enformer or deep CNN to represent the underlying mechanisms, and we can use a simple two-layer convolutional neural network with Bayesian parameters.\n",
    "\n",
    "### Baselines\n",
    "\n",
    "Three kinds of baselines would be useful:\n",
    "1. Trivial memorisation baseline such as computing average signal for the same sequence per experimental batch ignoring cell type.\n",
    "2. Best possible performance memorisation baseline such as replicate concordance or computing average signal for the same sequence per cell type.\n",
    "3. Previously published packages (architecture + implementation). This helps understand how methods that worked and were published on other data look on this data.\n",
    "\n",
    "When the task ignores cell states and only considers DNA, we need to consider baselines that test whether the model learns trivial or technically-driven pattern in DNA sequences - instead of learning the regulatory code of interest. This test is partially achieved by testing on previously unseen DNA sequences which can rule out severe overfitting to training sequences. \n",
    "\n",
    "It is easier to construct a best possible performance baseline using biological and/or technicical replicates - which as far as I can see is not easily accessible for this data. Constructing an alternative model that optimally prepresent sequence patterns is the modelling goal in itself\n",
    "\n",
    "We are left with trivial baselines such as:\n",
    "1. Using CG dinucleotide (aka k=2 K-mer) content as a predictor.\n",
    "2. Computing the average signal for N most similar training sequences with similar k-mer compositions (eg k=1...4).\n",
    "\n",
    "NOTE: I don't know why the authors of the underlying package did not use PyTorch Lightning but implemented their own trainers. I just used ther core package. In a real project I would use scvi-tools and PyTorch Lightning.\n",
    "NOTE 2: the code seems to be limited by batch loading rather than GPU compute."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb5bc3df-3b04-44f0-b1c0-a99993166ab9",
   "metadata": {},
   "source": [
    "#### Install environment\n",
    "\n",
    "```bash\n",
    "export PYTHONNOUSERSITE=\"aaaaa\"\n",
    "conda env create -n dream -f environment.yml\n",
    "conda activate dream\n",
    "python -m ipykernel install --user --name=dream --display-name='Environment (dream)'\n",
    "```\n",
    "\n",
    "```bash\n",
    "export PYTHONNOUSERSITE=\"aaaaa\"\n",
    "conda env create -n dream2 -f environment.yml\n",
    "conda activate dream2\n",
    "python -m ipykernel install --user --name=dream2 --display-name='Environment (dream2)'\n",
    "```\n",
    "\n",
    "#### Load JASPAR motifs\n",
    "\n",
    "```bash\n",
    "wget https://jaspar.elixir.no/download/data/2024/CORE/JASPAR2024_CORE_fungi_non-redundant_pfms_meme.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36168a15-1a5d-4783-9673-ee00667c8928",
   "metadata": {},
   "source": [
    "# Import libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8cc7498-bf9d-4b12-96e9-20ce804d5ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/team283/vk7/software/miniconda3farm5/envs/dream/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from prixfixe.autosome import AutosomeDataProcessor, AutosomeFinalLayersBlock, AutosomeTrainer, AutosomePredictor\n",
    "from prixfixe.bhi import BHIFirstLayersBlock, BHICoreBlock\n",
    "from prixfixe.unlockdna import UnlockDNACoreBlock\n",
    "from prixfixe.prixfixe import PrixFixeNet\n",
    "from prixfixe.bayesian import BayesianFinalLayersBlock, BayesianTrainer, setup_pyro_model, get_jaspar_motifs, motif_dict_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c742eb34-bf37-4241-99e5-b24da9119744",
   "metadata": {},
   "source": [
    "# Initialize paths and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1914474-3bd0-434c-add7-283c313abcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA_PATH = \"data/demo_train.txt\" #change filename to actual training data\n",
    "# VALID_DATA_PATH = \"data/demo_val.txt\" #change filename to actual validaiton data\n",
    "TRAIN_DATA_PATH = \"../train.txt\" # 6065325\n",
    "VALID_DATA_PATH = \"../val.txt\" #change filename to actual validaiton data\n",
    "\n",
    "\n",
    "TRAIN_BATCH_SIZE = 4096 # replace with 1024, if 1024 doesn't fit in gpu memory, decrease by order of 2 (512,256)\n",
    "BATCH_PER_EPOCH = int(np.ceil(6065325 / TRAIN_BATCH_SIZE)) #replace with total amount of possible batches in the training data\n",
    "N_PROCS = 8\n",
    "VALID_BATCH_SIZE = 4096\n",
    "BATCH_PER_VALIDATION = int(np.ceil(673925 / VALID_BATCH_SIZE)) #replace with total amount of possible batches in the validaiton data\n",
    "PLASMID_PATH = \"data/plasmid.json\"\n",
    "SEQ_SIZE = 150\n",
    "NUM_EPOCHS = 80 #replace with 80\n",
    "CUDA_DEVICE_ID = 0\n",
    "lr = 0.005 # 0.001 for attention layers in coreBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a57a19b-62c3-4d0f-9f00-d5e8989420df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 15, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaspar_dict = get_jaspar_motifs(fixed_motifs_path=\"./JASPAR2024_CORE_fungi_non-redundant_pfms_meme.txt\", genome='yeast')\n",
    "jaspar_array = motif_dict_to_array(jaspar_dict, 15)\n",
    "\n",
    "jaspar_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07429083-4ebb-42ee-a3b9-e9bdebd6d881",
   "metadata": {},
   "source": [
    "# DataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7888fb-a823-411f-b091-dadc6569b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator()\n",
    "generator.manual_seed(2147483647)\n",
    "\n",
    "dataprocessor = AutosomeDataProcessor(\n",
    "    path_to_training_data=TRAIN_DATA_PATH,\n",
    "    path_to_validation_data=VALID_DATA_PATH,\n",
    "    train_batch_size=TRAIN_BATCH_SIZE, \n",
    "    batch_per_epoch=BATCH_PER_EPOCH,\n",
    "    train_workers=N_PROCS,\n",
    "    valid_batch_size=VALID_BATCH_SIZE,\n",
    "    valid_workers=N_PROCS,\n",
    "    shuffle_train=True,\n",
    "    shuffle_val=False,\n",
    "    plasmid_path=PLASMID_PATH,\n",
    "    seqsize=SEQ_SIZE,\n",
    "    generator=generator,\n",
    "    dataset_kwargs={\n",
    "        \"use_single_channel\": False,\n",
    "        \"use_reverse_channel\": False,\n",
    "    } \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ac15af-6475-4bb3-adec-bd6786483361",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(dataprocessor.prepare_train_dataloader())\n",
    "\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9ec8b-36ce-49d6-bacc-b78eecec5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd47929-4ada-4f7c-b46e-fcafdec8d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f0913c-25d7-46ed-8ab2-dc8f0f6e65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['y_probs'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50580fc-281f-410e-a67a-661bf85a9275",
   "metadata": {},
   "source": [
    "# Prix-Fixe Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff673d6-f26f-4cdd-be57-f1a2be4c4916",
   "metadata": {},
   "source": [
    "### DREAM-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184d418d-70f9-4ee9-9a03-0dd437364677",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = BayesianFinalLayersBlock(\n",
    "    in_channels=4,\n",
    "    seqsize=batch['x'].shape[-3],\n",
    "    n_out=18,\n",
    "    fixed_motifs=np.expand_dims(jaspar_array, -3).astype('float32'),\n",
    "    level2_width=40,\n",
    "    tf_affinity_scanner_kwargs={\n",
    "        \"use_reverse_complement\": True,\n",
    "        \"pool_window\": 2,\n",
    "        \"shift_seq_val\": 3,\n",
    "        \"padding\": \"valid\",\n",
    "        \"n_binding_modes\": 1,\n",
    "    }\n",
    ")\n",
    "model = PrixFixeNet(\n",
    "    first=None,\n",
    "    core=None,\n",
    "    final=final,\n",
    "    generator=generator\n",
    ")\n",
    "setup_pyro_model(\n",
    "    dataloader=dataprocessor.prepare_train_dataloader(), \n",
    "    pl_module=model.final,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70dbee9-e604-4835-9e9c-cd3dcc62e9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, (1, 4, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c68ff-c05e-459a-9d4f-f100abaa9cc8",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96ddc3-8eb1-489f-9960-9d40e21296fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir=\"data/bayesian_model_weights_2bp_40width_full0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f32b0-0735-493e-bdac-a3e21e24d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = AutosomeTrainer(\n",
    "    model,    \n",
    "    device=torch.device(f\"cuda:{CUDA_DEVICE_ID}\"), \n",
    "    model_dir=model_dir,\n",
    "    dataprocessor=dataprocessor,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040dc14d-1f7f-4ae4-af38-ac8326cf6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69962bbf-3577-492e-973d-4a70a3324dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.best_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d72e6-68b7-4b02-8bc7-c05b807daf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.save(model.state_dict(), os.path.join(model_dir, 'model_best.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42462ab7-166f-438c-a5ae-022c3aeb0770",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45630855-d46a-4982-9733-f46cad9d88b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(model_dir, 'model_best.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98fa2775-5b49-4096-bc52-dd14c64fd7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.441959381103516"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "predictor = AutosomePredictor(\n",
    "    model=model, \n",
    "    model_pth=f'{model_dir}/model_best.pth', \n",
    "    device=torch.device(f\"cuda:0\"),\n",
    "    use_reverse_channel=False,\n",
    "    use_single_channel=False,\n",
    ")\n",
    "dna = \"TGCATTTTTTTCACATC\"+ ''.join(random.choice('ACGT') for _ in range(80)) + \"GGTTACGGCTGTT\"\n",
    "predictor.predict(dna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf378bf9-5d44-4924-bc2e-50662fb8542a",
   "metadata": {},
   "source": [
    "# Prediction on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b60c500-3751-4908-8a88-bdbe67640b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:05<00:00, 198.23it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('data/filtered_test_data_with_MAUDE_expression.txt', header=None, sep='\\t')\n",
    "\n",
    "from tqdm import tqdm\n",
    "pred_expr = []\n",
    "for seq in tqdm(test_df.iloc[:, 0]):\n",
    "    pred_expr.append(predictor.predict(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39bb7301-a9e5-4f4c-8892-83fae6182312",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_expr = np.array(pred_expr)\n",
    "pred_expr[np.isnan(pred_expr)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69d32e96-34b3-469b-804b-8ef298eabe13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=-0.04612572283912364, pvalue=0.14495774558928934) SignificanceResult(statistic=-0.049899154035730954, pvalue=0.1148050395554289)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "print(pearsonr(pred_expr, list(test_df.iloc[:, 1])), spearmanr(pred_expr, list(test_df.iloc[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4705a0-d045-43f0-840e-8da9e93ee381",
   "metadata": {},
   "source": [
    "# Score your submission on DREAM Challenge test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "166d2022-69b3-40d1-9b07-227790187756",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1000 is out of bounds for axis 0 with size 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pred_expr = pd.read_csv('data/sample_submission.txt', sep = '\\t', header = None).iloc[:,1]\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprixfixe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate_predictions\n\u001b[0;32m----> 3\u001b[0m \u001b[43mevaluate_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_expr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nfs/team205/vk7/sanger_projects/collaborations/retro_test/random-promoter-dream-challenge-2022/prixfixe/evaluation.py:115\u001b[0m, in \u001b[0;36mevaluate_predictions\u001b[0;34m(expressions, discard_public_leaderboard_indices)\u001b[0m\n\u001b[1;32m    112\u001b[0m     final_all \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(GROUND_TRUTH_EXP)))\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Calculate correlations\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m pearson, spearman \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_correlations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpressions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGROUND_TRUTH_EXP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m high_pearson, high_spearman \u001b[38;5;241m=\u001b[39m calculate_correlations(high, expressions, GROUND_TRUTH_EXP)\n\u001b[1;32m    117\u001b[0m low_pearson, low_spearman \u001b[38;5;241m=\u001b[39m calculate_correlations(low, expressions, GROUND_TRUTH_EXP)\n",
      "File \u001b[0;32m/nfs/team205/vk7/sanger_projects/collaborations/retro_test/random-promoter-dream-challenge-2022/prixfixe/evaluation.py:39\u001b[0m, in \u001b[0;36mcalculate_correlations\u001b[0;34m(index_list, expressions, GROUND_TRUTH_EXP)\u001b[0m\n\u001b[1;32m     36\u001b[0m GROUND_TRUTH \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m index_list:\n\u001b[0;32m---> 39\u001b[0m     PRED_DATA[\u001b[38;5;28mstr\u001b[39m(j)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mexpressions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     40\u001b[0m     GROUND_TRUTH[\u001b[38;5;28mstr\u001b[39m(j)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(GROUND_TRUTH_EXP[j])\n\u001b[1;32m     42\u001b[0m pearson \u001b[38;5;241m=\u001b[39m pearsonr(\u001b[38;5;28mlist\u001b[39m(GROUND_TRUTH\u001b[38;5;241m.\u001b[39mvalues()), \u001b[38;5;28mlist\u001b[39m(PRED_DATA\u001b[38;5;241m.\u001b[39mvalues()))[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1000 is out of bounds for axis 0 with size 1000"
     ]
    }
   ],
   "source": [
    "# pred_expr = pd.read_csv('data/sample_submission.txt', sep = '\\t', header = None).iloc[:,1]\n",
    "from prixfixe.evaluation import evaluate_predictions\n",
    "evaluate_predictions(pred_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e7209-5d39-4637-9c93-27d8b2c071c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (dream)",
   "language": "python",
   "name": "dream"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
